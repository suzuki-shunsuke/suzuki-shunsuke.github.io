<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>melody</title>
    <link>https://suzuki-shunsuke.github.io/</link>
    <description>Recent content on melody</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <lastBuildDate>Sun, 07 Jul 2019 08:20:00 +0900</lastBuildDate>
    
	<atom:link href="https://suzuki-shunsuke.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Fagott - Golang HTTP client testing framework</title>
      <link>https://suzuki-shunsuke.github.io/fagott/</link>
      <pubDate>Sun, 07 Jul 2019 08:20:00 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/fagott/</guid>
      <description>Go の HTTP client のテストフレームワークを作ったので紹介します。
https://github.com/suzuki-shunsuke/fagott
執筆時点のバージョンは v0.3.0 です。
 リクエストパラメータのテスト HTTP サーバのモッキング  を目的としています。
比較的実践的なサンプルとして、ユーザーを作成する簡単な API client とそのテストを書いたので参考にしてください。
 https://github.com/suzuki-shunsuke/fagott/blob/master/examples/create_user.go https://github.com/suzuki-shunsuke/fagott/blob/master/examples/create_user_test.go#L17-L53  元々自分はこの目的のために h2non/gock を使っていました。 ただ、 gock だとリクエストがマッチしなかったときに、なぜマッチしないのかがわからず、調査に困るという問題がありました。
そこで fagott では request に対し、matcher と tester という概念を導入し、 matcher でマッチしたリクエストを tester でテストするというふうにしました。 テストでは内部で stretchr/testify の assert を使っており、テストに失敗したときになぜ失敗したのかが分かりやすく出力されるようになっています。
例えば以下の例は、リクエストの Authorization header にトークンがセットされていなかった場合のエラーメッセージです。
=== RUN TestClient_CreateUser --- FAIL: TestClient_CreateUser (0.00s) tester.go:168: Error Trace: tester.go:168 tester.go:32 transport.go:25 client.go:250 client.go:174 client.go:641 client.go:509 create_user.go:45 create_user_test.go:56 Error: Not equal: expected: []string{&amp;quot;token XXXXX&amp;quot;} actual : []string{&amp;quot;token &amp;quot;} Diff: --- Expected +++ Actual @@ -1,3 +1,3 @@ ([]string) (len=1) { - (string) (len=11) &amp;quot;token XXXXX&amp;quot; + (string) (len=6) &amp;quot;token &amp;quot; } Test: TestClient_CreateUser Messages: the request header &amp;quot;Authorization&amp;quot; should match service: http://example.</description>
    </item>
    
    <item>
      <title>Drone で「ビルド実行時にパラメータを渡す」っぽいことをする</title>
      <link>https://suzuki-shunsuke.github.io/how-to-imitate-jenkins-parameterized-build-at-drone/</link>
      <pubDate>Thu, 20 Jun 2019 17:50:11 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/how-to-imitate-jenkins-parameterized-build-at-drone/</guid>
      <description>Jenkins では parameterized build という機能で、ビルド実行時に Web UI からパラメータを指定することができます。 Drone では基本的に Git のイベントをフックして動くので同様の機能はありません。
自分はこのような機能は特に必要ないと思っていますが、 こういった機能がないから Drone を使わないという人も中にはいるので、 Drone でもちょっとした工夫でそれっぽいことは出来るんじゃないかと思い、簡単なサンプルを書いてみました。
一応言っておくと、 Jenkins の parameterized build を完全に代替するようなものではありません。
https://github.com/suzuki-shunsuke/example-drone-build-parameter
以下のファイルが必要です。
 build_params/params.sh.tpl: ビルドパラメータを記述ファイルのテンプレート scripts/deploy.sh: デプロイ時に実行するスクリプト .drone.yml: Drone の設定ファイル  スクリプトを実行してデプロイします。
$ bash scripts/deploy.sh  するとパラメータを記述するファイルがエディタで開きます。
https://github.com/suzuki-shunsuke/example-drone-build-parameter/blob/master/scripts/deploy.sh#L12-L17
パラメータを記述し、エディタを閉じます。
するとそのファイルがコミットされ、新しいタグが作成され、コミットとタグがリモートにプッシュされます。
https://github.com/suzuki-shunsuke/example-drone-build-parameter/blob/master/scripts/deploy.sh#L27-L35
Drone でタグをフックしてビルドが実行されます。
https://github.com/suzuki-shunsuke/example-drone-build-parameter/blob/master/.drone.yml#L13-L17
ビルドではコミットされたパラメータの設定ファイルを読み込むことでビルドにパラメータを渡せます。
https://github.com/suzuki-shunsuke/example-drone-build-parameter/blob/master/.drone.yml#L10
こうすることでビルドにパラメータを渡すことができます。 パラメータの設定ファイルはコミットされるので Git で管理できるというのも特徴です。
https://github.com/suzuki-shunsuke/example-drone-build-parameter/blob/master/build_params/2019-07-07T10-04-02JST/params.sh
上記のスクリプトではパラメータの設定ファイルとしてシェルスクリプトで環境変数を定義していますが、 シェルスクリプトである必要性はなく、例えば JSON ファイルを記述してビルドで JSON ファイルを読み込んでもよいし、 パラメータを選択させるようなことがしたければ fzf のようなものを使ってもよいし、 いくらでも改善できます。
以上、簡単な tips でした。</description>
    </item>
    
    <item>
      <title>Drone v0.8 の .drone.yml を v1 の .drone.jsonnet に変換するツールを作った</title>
      <link>https://suzuki-shunsuke.github.io/drone-jsonnet-generator/</link>
      <pubDate>Wed, 12 Jun 2019 07:40:45 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-jsonnet-generator/</guid>
      <description>Drone v0.8 の .drone.yml を v1 の .drone.jsonnet に変換するツールを作ったので紹介します。
https://github.com/suzuki-shunsuke/drone-jsonnet-generator
背景 https://docs.drone.io/user-guide/pipeline/migrating/
Drone は v0.8 から v1 で .drone.yml のフォーマットが大きく変わっています。 Drone v1 ではビルド実行時に自動で変換しているため、v0.8 の .drone.yml でもそのまま動きます(matrix builds も動きます)。
そのため、Drone v0.8 から v1 に移行する際、すぐに .drone.yml を修正しなくても問題ないのですが、 v1 独自の機能が出てきた場合 v0.8 のフォーマットの場合利用できないかもしれませんし、 いつまでも古いままだと気持ち悪いので出来るならフォーマットを変換したいです。
drone-cli ではフォーマットを変換する drone convert というコマンドが提供されています。
ただし、 drone convert は matrix build を multiple pipeline に変換するのですが、 非常に冗長になります。 そのため、jsonnet を利用することが推奨されています。
https://docs.drone.io/user-guide/pipeline/migrating/
 The above syntax can be quite verbose if you are testing a large number of variations.</description>
    </item>
    
    <item>
      <title>.drone.jsonnet と .drone.yml を比較する Drone plugin を作った</title>
      <link>https://suzuki-shunsuke.github.io/drone-plugin-jsonnet-check/</link>
      <pubDate>Sat, 01 Jun 2019 08:34:10 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-plugin-jsonnet-check/</guid>
      <description>久しぶりに Drone plugin を作ったので紹介します。
https://www.github.com/suzuki-shunsuke/drone-plugin-jsonnet-check
.drone.jsonnet から .drone.yml を生成していて、両方を Git で管理している場合に、 .drone.jsonnet と .drone.yml の状態が一致しているかテストするための plugin です。
Drone v1 では matrix builds が廃止され、multiple pipeline が導入されました。 matrix builds を drone convert コマンドで multiple pipeline に変換すると、pipeline の数が多いほど冗長でメンテナンス性が悪くなります。 そこで公式では jsonnet で記述して .drone.yml に変換する方法が推奨されています。
https://docs.drone.io/user-guide/pipeline/migrating/
 To simplify your configuration we recommend using jsonnet.
 $ drone jsonnet --format --stream  jsonnet から yaml への変換は Jsonnet extension を使うと Drone がビルド実行時に自動で変換してくれるので .drone.yml を管理する必要はなくなりますが、 使っていない場合、 .drone.jsonnet と .</description>
    </item>
    
    <item>
      <title>go-jsoneq - 2つの値がJSONとして等しいか比較するGoライブラリ</title>
      <link>https://suzuki-shunsuke.github.io/go-jsoneq/</link>
      <pubDate>Thu, 23 May 2019 11:43:18 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/go-jsoneq/</guid>
      <description>https://github.com/suzuki-shunsuke/go-jsoneq
2つの値がJSONとして等しいか比較するGoライブラリを開発したので紹介します。
「2つの値がJSONとして等しい」とは、2つの値をそれぞれJSON文字列に変換したら、2つが表現するデータがおなじになるという意味です。
struct { Foo string `json:&amp;quot;foo&amp;quot;` }{ Foo: &amp;quot;bar&amp;quot;, }  と
map[string]interface{}{&amp;quot;foo&amp;quot;: &amp;quot;bar&amp;quot;}  を JSON に変換したらともに
{&amp;quot;foo&amp;quot;: &amp;quot;bar&amp;quot;}  になりますね。
json.Marshaler のテストや、 実際の JSON 文字列から構造体を定義したときにちゃんと定義できているかチェックするのに使えると思います。
jsoneq.Equal でやっていることは単純です。
 json.Marshal で []byte に変換 json.Unmarshal で []byte を map, array と primitive な型からなるオブジェクト(?)に変換 reflect.DeepEqual で比較  引数が []byte の場合は 1 は飛ばします。
GoDoc やサンプルを見れば使い方は簡単にわかると思います。
以上、簡単ですが、自作ライブラリの紹介でした。</description>
    </item>
    
    <item>
      <title>durl - 壊れたURLを検知するCLIツール</title>
      <link>https://suzuki-shunsuke.github.io/durl/</link>
      <pubDate>Sun, 28 Apr 2019 21:25:00 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/durl/</guid>
      <description>結構前に開発したツールですが、まだ記事にしてなかったので紹介します。
https://github.com/suzuki-shunsuke/durl
ファイル中の URL が壊れていないかチェックするツールです。 ファイル中の URL を抽出し、HTTPリクエストを投げてステータスコードが 2xx でないものがあった場合、異常終了します。
なお、ページ内リンク(アンカー)が壊れているものについては検知できません。
インストール Go製で、バイナリを GitHub Releases で公開しています。
https://github.com/suzuki-shunsuke/durl/releases
Docker イメージ https://quay.io/repository/suzuki_shunsuke/durl
busybox ベースの Docker イメージも提供しています。 CI で使うのに便利です。
使い方 durl init で設定ファイル .durl.yml を生成します。
$ durl init  durl check に対象ファイルパスのリストを標準入力として渡してください。 find コマンドなどと組み合わせると良いです。
https://github.com/suzuki-shunsuke/go-errlog/blob/v0.9.0/scripts/durl.sh#L9
find . \ -type d -name node_modules -prune -o \ -type d -name .git -prune -o \ -type d -name vendor -prune -o \ -type f -print | \ grep -v package-lock.</description>
    </item>
    
    <item>
      <title>毎週30分の技術共有会</title>
      <link>https://suzuki-shunsuke.github.io/2019-knowledge-share-meeting/</link>
      <pubDate>Sun, 17 Mar 2019 13:47:40 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/2019-knowledge-share-meeting/</guid>
      <description>自分が最近職場で行っている技術共有の取り組みについて紹介したいと思います。
背景 これまで自分は積極的に自分にとって新しい技術を取り入れてサービスの品質の向上に繋げてきました。 ただし、それらの技術に関して周りに十分に共有できていなかった側面がありました。
やっていること 毎週30分決まった時間にスライドを使って発表しています。 対象は同じ部署の希望者です。 枠は30分ですが、実質話しているのは20分くらいな気がします。 k8sのハンズオン的なこともやりました(そのときは30分で終わらないので2回に分けてやりました)。
話したいことはたくさんあるのですが、とりあえず大きなトピックとして以下の3つに絞っています。
 k8s(Rancher): オーケストレーション (いまここ) Drone: CI/CD Graylog: ログ収集  これまで話したこと・話す予定のこと k8s の初心者が k8s を本番運用を視野に入れつつ検証環境で使ってみるところまでを目指して話しています。
 なぜ k8s を使うのか(部署のコンテキストに合わせて導入意義を説明) k8s のリソース(Pod, Service, Deployment, etc) について k8s, Rancher ハンズオン(2回) 簡単なアプリケーションをデプロイしてみたり Logging (いまここ) モニタリング IP制限のかかった外部サービスへアクセスする方法  毎週30分というペース感について 以下のようなことを配慮しました。
 集中力が続くこと  60分は長すぎる  持続可能であること  1, 2 回やっただけでは意味がない 30分だけなら参加しやすい 準備のコストも現実的な範囲 30分と短めなので毎週やる。隔週とかだと頻度が少なすぎるし、1回飛ぶと1ヶ月空いてしまう   これまでの結果 特に大きな成果があるわけではないですが、 k8sに興味を持ちk8sを検証環境で使ってくれる人が出てきました。 共有会がk8s を触るきっかけになったのだとしたらそれだけでもやってよかったと思います。
また、自分自身学ぶこともありました。 Logging に関して自分は今まで Sidecar pattern を使っていたのですが、Cluster Level Logging への移行を検討するきっかけになりました。</description>
    </item>
    
    <item>
      <title>Rancherでusername が重複してログインできなくなった場合の解消方法</title>
      <link>https://suzuki-shunsuke.github.io/rancher-duplicated-user-name/</link>
      <pubDate>Sat, 16 Mar 2019 21:17:05 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/rancher-duplicated-user-name/</guid>
      <description>先日起こった Rancher のトラブルの解消方法について紹介したいと思います。 Rancher のバージョンは v2.1.6 です。 admin ユーザーでログインしようとしたところ、エラーが起こりました。 最初パスワードが間違っているのかと思い、パスワードリセットしたものの、解消しませんでした。
https://rancher.com/docs/rancher/v2.x/en/faq/technical/#how-can-i-reset-the-admin-password
エラーメッセージをよく見ると 500 エラーでした。そこで rancher のコンテナのログを見ました。
[ERROR] API error response 500 for POST /v3-public/localProviders/local?action=login. Cause: found more than one users with username admin  username が admin のユーザーが複数人いるからログインに失敗しているようです。 であれば、ユーザーを rename ないし delete すれば解消しそうです。 しかし Admin 権限を持っているのが admin しかいないため、ユーザーを rename したり delete するのが難しいです。
どうすればよいかと思って調べてたところ rancher のコンテナ内で kubectl コマンドを使うことで Rancher の Custom Resource を操作できそうなことを知りました。
https://qiita.com/yamamoto-febc/items/498b911611dd25351ad7
そこで 2 人いる admin の片方を rename することで解消しました。</description>
    </item>
    
    <item>
      <title>Goの設定管理で viper の代わりに confita を使う</title>
      <link>https://suzuki-shunsuke.github.io/use-confita/</link>
      <pubDate>Sat, 16 Feb 2019 18:38:45 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/use-confita/</guid>
      <description>Golang の設定管理のライブラリといえば viper が有名ですが、 confita も良さそうだったので紹介したいと思います。
confita の機能としては以下のようなものがあります。
 構造体に設定をマッピング flag や環境変数、設定ファイルに対応 複数の設定ファイルに対応  構造体に設定をマッピングすることで、https://github.com/go-playground/validator のようなライブラリを使って設定のバリデーションが出来ます。
また viper は v1.3.1 の時点で複数の設定ファイルを扱いにくいです。
 Viper can search multiple paths, but currently a single Viper instance only supports a single configuration file.
 k8s で ConfigMap と Secret を設定ファイルとして扱う場合、複数のファイルを扱えないと不便です。 その点 confita は複数の設定ファイルを問題なく扱えます。
以下はフラグで指定した複数の設定ファイルから設定を読み込む簡単なサンプルです。
import ( &amp;quot;context&amp;quot; &amp;quot;gopkg.in/go-playground/validator.v9&amp;quot; &amp;quot;github.com/heetch/confita&amp;quot; &amp;quot;github.com/heetch/confita/backend&amp;quot; &amp;quot;github.com/heetch/confita/backend/file&amp;quot; flag &amp;quot;github.com/spf13/pflag&amp;quot; ) func loadConfig(ctx context.Context) (Config, error) { cps := flag.StringSliceP(&amp;quot;config&amp;quot;, &amp;quot;c&amp;quot;, nil, &amp;quot;configuration file path&amp;quot;) flag.</description>
    </item>
    
    <item>
      <title>JS以外でのnpmの活用</title>
      <link>https://suzuki-shunsuke.github.io/use-npm/</link>
      <pubDate>Thu, 14 Feb 2019 21:34:22 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/use-npm/</guid>
      <description>npm は Node.js のパッケージマネージャーですが、自分はJS以外のプロジェクトでも使えると思っています。 実際、Goのアプリケーション、OSS、ansible role, playbook など種類を問わず、自分が管理している多くのリポジトリで使っています。 ただ、GoのOSSで npm 使っているのは自分以外で見たことはないですし、 正直あまり賛同はされないかなと思いますが、こういう考え方もあると思っていただけたらと思います。
npm を使う理由は
 Node製のツールを使うため npm scripts を使うため (今回書きたいのはこっち)  の2つあります。
Node製のツール  husky: Git Hookを設定 commitlint: commit メッセージのlint standard-version: コミットログによって Change Log を生成  などを使っています。 Nodeはバージョンの変化が速く、互換性が壊れたりとかも多い印象ですが、 グローバルにインストールしなくてもリポジトリごとに install 出来る(package.jsonで管理できる)のでその点は(特にチーム開発では)良いと思います。
npm scripts npm scripts によってそのリポジトリの開発に使うコマンド群を管理するということを自分はしています。
https://github.com/suzuki-shunsuke/gomic/blob/master/package.json
なにもツールを使わない場合に比べ、こうすることでチーム全体でコマンドを統一できますし、一連のコマンドをスクリプト化して npm scripts で実行できるようにするなど、自動化も促進されます。
ごく簡単な自動化の例ですが、tag を打つと同時にソースコード中のバージョン番号を更新するのを npm run tag v1.1.0 といったコマンドで出来るようにしています。 こうすることで tag とversionコマンドで出力されるバージョンが違うなんてことを防ぐことが出来ます。
https://github.com/suzuki-shunsuke/gomic/blob/master/scripts/tag.sh
また、オプションによって動作が変わるようなコマンドは npm scripts によって実行することでオプションを統一できます。 例えば gofmt は -s オプションの有無で結果が変わります。</description>
    </item>
    
    <item>
      <title>Golang の好きなところ</title>
      <link>https://suzuki-shunsuke.github.io/golang-good-point/</link>
      <pubDate>Sun, 10 Feb 2019 17:49:58 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/golang-good-point/</guid>
      <description>自分は 2017/8頃(曖昧)からメインで書く言語をPythonからGolangに変更しました。 Goを書き始めて割と早い段階でGoが一番好きになりました。 そこでなんで Go が好きなのかということを頑張って言語化しようと思います。
若干他の言語と比較する部分もありますが、決して他の言語をディスったり、 他の言語より優れているということが言いたいわけではないのでご了承ください。
 依存するものが小さく、バイナリ1つインストールするだけで良い  Prometheus の exporter とかインストールするの簡単 Docker Imageも最小限になる  静的型付け  ビルド出来ている時点で一定の信頼性が担保されている よく知らないコードを読んだり修正するときとかだいぶ有り難い  GoDocが素晴らしい  何もしなくてもライブラリのドキュメントが出来上がっている  ライブラリの公開が容易  GitHubに公開するだけ npm や pypi のようなレジストリがないので楽  go test とか go vet, gofmt みたいに標準ツールが揃っている コーディング規約で悩む必要がない lintツールが充実している  gometalinter とか使っておけば OK lintできる環境を構築するのにそこまで頑張らなくて良い  エラーハンドリングが暗黙的に省略できないので信頼性が高い  Goのエラーハンドリング嫌いって人もいるし、v2で改善されるって話も聞くけど、自分はむしろ好き(面倒なのは理解できるけど)  言語仕様がシンプル(客観的な根拠はないし、難しい部分もあるけど、そんな気がする)  メタプログラミング使った、魔術的なコードになりにくい  interface 使ってコードを疎結合にするのが書いてて気持ちいい 並列処理が書きやすい  </description>
    </item>
    
    <item>
      <title>go-error-handling-logging-practice v0.2</title>
      <link>https://suzuki-shunsuke.github.io/golang-logging-error-handling-practice-0.2.0/</link>
      <pubDate>Fri, 01 Feb 2019 22:26:13 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/golang-logging-error-handling-practice-0.2.0/</guid>
      <description>以前 Golang のロギング・エラーハンドリングについて書きました。
 https://suzuki-shunsuke.github.io/golang-logging-error-handling-practice/ https://github.com/suzuki-shunsuke/go-error-handling-logging-practice  それを少し v0.1 から v0.2 に互換性を壊す形でアップデートしようかと思います。 本記事ではその変更点について書きます。
変更点 関数のエラーに情報を付与する責務を関数に割り当てていたものを、呼び出し元に割り当てるようにします。
具体的には元々
func createUser(name string, age int) error { return errlog.Wrap(checkName(name), logrus.Fields{&amp;quot;age&amp;quot;: age}, &amp;quot;failed to create a user&amp;quot;) }  だったものが
func createUser(name string, age int) error { return errlog.Wrap(checkName(name), nil, &amp;quot;user name is invalid&amp;quot;) }  になります。
変更理由 メタ情報のフィールド名はコンテキストに依存します。 上記の例だとユーザー名というメタ情報のフィールド名は name より user_name や admin_name, owner_name としたほうが適切かもしれません。それは関数内部では分からず、呼び出し元でないと分かりません。呼び出し元でないとフィールド名の衝突が避けられないこともあるでしょう。
メッセージに関しても同様のことが言えます。 また、元々 v0.1 ではユーザーが定義した関数と
 標準関数やサードパーティのライブラリなど、プロジェクト外部で定義された関数 interface の関数やメソッド  を区別し、前者では関数側でエラーに情報を付与させる一方、後者では呼び出し元で情報を付与させるというふうにしていました。</description>
    </item>
    
    <item>
      <title>Terraform Providerで import を実装する方法</title>
      <link>https://suzuki-shunsuke.github.io/terraform-provider-graylog-import/</link>
      <pubDate>Fri, 25 Jan 2019 22:38:28 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/terraform-provider-graylog-import/</guid>
      <description>terraform provider graylog で alert condition と stream rule の import を実装しました。
 https://github.com/suzuki-shunsuke/go-graylog/pull/59 https://github.com/suzuki-shunsuke/go-graylog/pull/60  そこで import を実装する方法を紹介したいと思います。
terraform でリソースをimportするにはリソースがimportをサポートしている必要があります。 schema.Resource の Importer フィールドですね。リソースがIDだけでGet出来る場合、schema.ImportStatePassthroughを使えば終わりです。 一方、Graylogのalert condition や stream rule はIDだけでなく、stream id も必要になります。 terraform import コマンドは1つの引数しか取らないため、サポートできないのでは？と以前まで思っていました。 そういった場合、次のようにStateFuncを実装すればサポートできます。
https://github.com/suzuki-shunsuke/go-graylog/pull/59/commits/baee1165f49d2bc21b6ea7551ceff6b7daf01543#diff-f41be2a3640efd12ad4e808d77c5c8d5
# &amp;quot;/&amp;quot; で区切って stream id と ID を渡す $ terraform import graylog_alarm_callback.test 5bb1b4b5c9e77bbbbbbbbbbb/5c4acaefc9e77bbbbbbbbbbb  区切り文字は何でも良いのでしょうが、公式のprovider が &amp;ldquo;/&amp;rdquo; で区切っていたのでそれに従うことにしました。
https://www.terraform.io/docs/providers/google/r/spanner_database.html#import
https://godoc.org/github.com/hashicorp/terraform/helper/schema#ImportStatePassthrough の実装を見てみれば分かりますが、 StateFunc の中では GET API を叩いてリソースを取得したりはしません。 terraform import コマンドの標準出力を見ると分かりますが refresh を実行しているのでそこでGETしているようです。 StateFunc は *schema.</description>
    </item>
    
    <item>
      <title>GithubをFree Planにダウングレードした</title>
      <link>https://suzuki-shunsuke.github.io/downgrade-github-plan/</link>
      <pubDate>Sun, 20 Jan 2019 12:27:26 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/downgrade-github-plan/</guid>
      <description>GitHub のプラン体系が変わり、無料プランでも無制限でprivate repositoryが作れるようになりました。
https://github.blog/2019-01-07-new-year-new-github/
そこで無料プランにダウングレードすることにしました。
 https://help.github.com/articles/downgrading-your-github-billing-plan/ https://blog.jnito.com/entry/2019/01/09/081913  無料プランではwikiはpublic repositoryでしか使えないので、 private repository の wiki を 移行することにしました。
private なソースコード(サービス)のためのwikiではなく、 個人的なメモが書いてあるだけだったので移行することに特に問題はありませんでした。
全 private repository の wiki を clone そこでまずはそういった wiki を clone して一つのリポジトリにまとめることにしました。
https://github.com/suzuki-shunsuke/foo の wiki は https://github.com/suzuki-shunsuke/foo.wiki で clone できます。
次のようなコマンドを実行し、private repositoryのwikiを全部cloneしました。
https://developer.github.com/v3/repos/#list-your-repositories
curl &amp;quot;https://api.github.com/user/repos?access_token=$GITHUB_TOKEN&amp;amp;visibility=private&amp;quot; | jq -r &#39;.[].html_url&#39; | xargs -I{} -n 1 git clone {}.wiki  wikiが存在しないものに関しては clone に失敗します。 API で wiki のリストが取得できると良かったんですが、 wikiに関するAPIはなさそうです。
また /user/repos API のレスポンスの has_wiki はwikiが存在しなくても、wikiが無効化されてなければ true なようです。</description>
    </item>
    
    <item>
      <title>Golangにおけるエラーハンドリングとロギングのプラクティス</title>
      <link>https://suzuki-shunsuke.github.io/golang-logging-error-handling-practice/</link>
      <pubDate>Tue, 25 Dec 2018 21:51:41 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/golang-logging-error-handling-practice/</guid>
      <description>2018-12-30 追記 この記事を元にドキュメントを書いてみました。
https://github.com/suzuki-shunsuke/go-error-handling-logging-practice
追記ここまで
Golang でエラーハンドリングとロギングをしてきて自分の中で固まりつつあるプラクティスを明文化します。 明文化することで以下のことを目指します。
 迷いをなくす コードの一貫性を保つ コーディング規約とすることでレビューの品質を上げる(自動化は出来ないけど) コードの品質を上げる(コードがゴチャつかなくなる) 適切にエラーをロギングする(必要十分な情報をログとして残す)  またエラーハンドリングとロギングのためのライブラリを自作しているのでそれも紹介します。
https://github.com/suzuki-shunsuke/go-errlog
ロギングに関する関連記事 この記事を書く前に軽くググってみただけでちゃんと読んでないのですが、 興味のある人は読んでみてください。
 https://logmatic.io/blog/our-guide-to-a-golang-logs-world/ https://www.loggly.com/blog/think-differently-about-what-to-log-in-go-best-practices-examined/ https://dave.cheney.net/2015/11/05/lets-talk-about-logging https://postd.cc/go-best-practices-2016/#logging-and-instrumentation  ログレベルは分ける ログレベルでwarningとかいらないという意見もありますが、自分は必要だと思っています。 自分は以下のログレベルを使い分けます。
 debug: あまり使わない。調査目的で一時的に埋め込むログ。調査が終わったら出力しないようにする。一時的でないものはinfoにする info: エラーでないログ。イベント、処理の開始時や終了を記録するのに使うことが多い warn: 4xx系のエラー。それが起こっただけではアラートを飛ばさないが、数が通常時より多い場合はバグかUIに問題があってユーザーが間違えやすくなっている可能性があるのでアラートを飛ばす error: 5xx系のエラー。アラートを飛ばす(閾値は調整) fatal: 処理継続が不可能な致命的なエラー。システムを止める  書いてから思いましたが、これに関しては標準的な使い分けのルールがありそうですね(要調査)。。
logrus を使ってログを構造化する 前提としてwebシステムやバッチシステムなどを想定しています。CLIツールならば話は変わるでしょう。 JSONフォーマットで出力してfluentdでElasticsearchにフォワードするのが個人的によくあるパターンです。
go-errlogもlogrusの使用を前提としています。
ロギングのライブラリは他にも色々あるので、logrusで満足できない人は以下から探してみるとよいでしょう。
https://github.com/avelino/awesome-go#logging
エラーログは中央集権的に main に近い所で出力する エラーログをどこで出力するかですが、原則中央集権的に main に近い所で出力します。 因みに中央集権的という表現は echo の centralized error handling からもじっています。
https://echo.labstack.com/guide/error-handling
error が発生してもすぐログを吐くのではなく、error を関数の戻り値として返し、ロギングする責務を親に委譲します。 Goでは以下のようなイディオムがよく見られますね。
if err !</description>
    </item>
    
    <item>
      <title>GraylogのAlertの課題</title>
      <link>https://suzuki-shunsuke.github.io/graylog-alert-issue/</link>
      <pubDate>Wed, 19 Dec 2018 21:02:11 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/graylog-alert-issue/</guid>
      <description> Graylogを運用してきて感じているAlert機能周りの課題をリストアップします。 自分のGraylogの理解が不十分で勘違いしている部分もあるかもしれませんが、ご了承ください。 Graylogのバージョンは 2.5.0 です。 ここでいう「メンション」とは、Slackのようなチャットツールのメンションを指します。 リストの詳細を書きだしてみたものの、リストだけでだいたい言いたいことが言えてしまっていたのと、単なる愚痴っぽくなってしまったので、 リストだけに留めます。
2018-12-31 追記 元々 Alert Condition, Notification の APIがないと勘違いしていたのですが、 実はちゃんとあったので terraform で管理できるように go-graylog を更新しました。
 https://github.com/suzuki-shunsuke/go-graylog/pull/50 https://github.com/suzuki-shunsuke/go-graylog/pull/52 https://github.com/suzuki-shunsuke/go-graylog/blob/master/terraform/docs/alarm_callback.md https://github.com/suzuki-shunsuke/go-graylog/blob/master/terraform/docs/alert_condition.md  課題リスト  APIでAlert Condition, Notificationを管理できない  APIがないので terraform でサポートも出来ない 数が増えるとWeb UIでは管理が辛い・修正漏れや設定ミスが出やすい  Condition, NotificationがStreamに紐づく  ConditionによってNotificationを変えられない 条件に応じてアラートの文面・通知先・メンション先・メンションの有無を変えられない (正確にはテンプレートエンジンで頑張ればある程度対応できるかもしれないが、個人的にはテンプレートそのものを切り替えたい) ConditionやNotificationを複数のStreamで使い回せない  (少なくとも標準機能では)時間帯によってアラートの挙動を変更できない  夜中にはアラートを飛ばさない・メンションをつけないといったことが出来ない 一時的にアラートを止められない  Pluginを使うにしてもどれを使ったら良いか分からない  もっとGraylogがメジャーになれば状況も変わるかもしれない   </description>
    </item>
    
    <item>
      <title>Graylog の Terraform を CI/CDで実行する</title>
      <link>https://suzuki-shunsuke.github.io/graylog-terraform-ci/</link>
      <pubDate>Fri, 07 Dec 2018 08:22:49 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/graylog-terraform-ci/</guid>
      <description>以前 Graylog を Terraform で管理する記事を書きました。
https://suzuki-shunsuke.github.io/graylog-terraform/
今回はそれを CI/CD で実行できるようにした話です。
ただし、今回の内容は Graylog に限らず Terraform を CI/CD で実行する方法として使えると思います。
今回実現したのは以下のことです。
 PR時にテストをする plan/* tag を push すると terraform plan が実行される apply/* tag を push すると terraform apply が実行され、tfstate がコミット、プッシュされる  ソースコード https://github.com/suzuki-shunsuke/example/tree/master/graylog-terraform に置いておきました。
 https://github.com/suzuki-shunsuke/example/blob/master/graylog-terraform/role.tf#L13-L25 https://github.com/suzuki-shunsuke/example/blob/master/graylog-terraform/user.tf#L12-L21 https://github.com/suzuki-shunsuke/example/blob/master/graylog-terraform/.drone.yml https://github.com/suzuki-shunsuke/example/blob/master/graylog-terraform/terraform.tfvars.tpl https://github.com/suzuki-shunsuke/example/blob/master/graylog-terraform/drone_pipeline_commands/git.sh  CI/CD用の user, role を作成する まずは role を作成します。
resource &amp;quot;graylog_role&amp;quot; &amp;quot;terraform&amp;quot; { name = &amp;quot;terraform&amp;quot; description = &amp;quot;terraform&amp;quot; permissions = [ &amp;quot;dashboards:*&amp;quot;, &amp;quot;indexsets:*&amp;quot;, &amp;quot;inputs:*&amp;quot;, &amp;quot;roles:*&amp;quot;, &amp;quot;streams:*&amp;quot;, &amp;quot;users:*&amp;quot;, ] }  permission は terraform で管理するリソースのみ付与しますが、 それでも結構強い権限を付与するので取扱に注意してください。</description>
    </item>
    
    <item>
      <title>molecule でansible の role と playbook をテストする</title>
      <link>https://suzuki-shunsuke.github.io/ansible-molecule/</link>
      <pubDate>Thu, 06 Dec 2018 23:08:04 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/ansible-molecule/</guid>
      <description>ansible 専用の testing ツール molecule を紹介します。 molecule の公式ドキュメント以外の情報は少ないので、参考になれば幸いです。
以前 Docker を使って ansible のテストをする方法を紹介しました。
https://suzuki-shunsuke.github.io/test-ansible-on-docker/
この際は Docker Compose と簡単なシェルスクリプトを使って実現しました。 これはこれでブラックボックスな部分がなく、学習コストも低くて悪くないので興味のある方はそちらもご参照ください。
molecule は ansible 専用の testing ツールです。 基本的に playbook というより role 用のツールですが、playbookのテストも工夫すれば出来ます。
 情報が少ない 公式ドキュメントも分かりづらい部分がある コマンドがエラー吐いて失敗した際に、ググっても情報が出てこないので辛い  という風に辛い部分もありますが、
 star数はそれなりにある ansible の公式のプロジェクトである https://github.com/ansible/molecule/ geerlingguy さんも使ってる  という風に良い面もあります。
それでは使っていきましょう。
インストール https://molecule.readthedocs.io/en/latest/installation.html
$ pip install molecule  Docker を使う場合 docker-py も必要です。
$ pip install docker-py  role のテスト playbookに比べて role のテストは簡単です。
role のディレクトリ(tasksやfilesなどがあるディレクトリ)に移動してコマンドを実行します。</description>
    </item>
    
    <item>
      <title>GraylogをTerraformで管理する</title>
      <link>https://suzuki-shunsuke.github.io/graylog-terraform/</link>
      <pubDate>Sat, 01 Dec 2018 14:56:00 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/graylog-terraform/</guid>
      <description>Graylogのリソースを terraform で管理するために作った terraform provider を紹介します。 Graylogとは何かはこちらを読んでください。
Graylogには様々なリソースがあります。
 User Role Input Index Set Stream Stream Rule Dashboard Alert etc  これらのリソースはWeb UIから作成したり出来るわけですが、 Web UIでポチポチするのは疲れますし、ソースコードで管理したいものです(Infrastructure as Code)。 また、Web UIからでは細かな権限管理は出来ず(限られた権限管理しか出来ない)、APIを使ってする必要があります。
APIを使って管理できるツールを探したものの見つからなかったので、 APIを使ってGraylog用のterraform providerを自作しています。
https://github.com/suzuki-shunsuke/go-graylog/tree/master/terraform
GraylogのAPIの種類は非常に多く、残念ながらカバーできているのは一部だけですが、以下のようなものをサポートしています。
 Alert Condition Alert Notification (Alarm Callback) Input User Role Index Set Stream Stream Rule Dashboard Ldap Setting  Role はサポートしているので権限管理は問題なく出来ます。 Dashboard Widget もサポートしたいです。
出来れば Alert の設定も出来ると良いのですが、Alertに関するCRUD APIが提供されていない(GETのみ)ので、サポートできません。
terraform を使った管理方法 以下では自分の管理方法を紹介します。
https://github.com/suzuki-shunsuke/example/tree/master/graylog-terraform
にサンプルが置いてあります。
基本はプロジェクトごとに
 Index Set, Stream, Role といったリソースを作成 User に Role を付与  という流れになります。</description>
    </item>
    
    <item>
      <title>Graylog で log を管理する</title>
      <link>https://suzuki-shunsuke.github.io/graylog/</link>
      <pubDate>Tue, 27 Nov 2018 16:40:33 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/graylog/</guid>
      <description>Java 製の OSS ログ管理システム Graylog の紹介です。 Graylog については幾つかに分けて記事を書きたいと思います。 今回はGraylogの入門的な内容になります。
なお、本記事中で「現在」「現時点」といった場合、特に断りがなければ記事執筆時点 2018-11-27 を指します。
Graylog のバージョン 検証に用いるGraylogのバージョンは 2.4.6 になります。
OSSバージョンとEnterpriseバージョンがありますが、本記事ではOSSバージョンを使用します。
Graylog とは  https://www.graylog.org/ https://github.com/Graylog2/graylog2-server  Kibana と Elasticsearch(以下ES) を使ったことがある人は、Kibanaに代わるものだと思っていただくとイメージしやすいかと思います。 ログはGraylogそのものが保持するのではなく、ESにインデキシングされます。 Kibana同様、ESに収集されたログを検索したり、ダッシュボードを作ったり出来ます。 ダッシュボードに関してはKibanaのほうが優れているようにも思えますが、 Graylogは認証・認可によりダッシュボードやログを操作できる人を制限・管理することが出来ます。
Graylogでログを管理する場合、ユーザーは直接ESにはログを送らず、Graylogを経由して送ります。 ESに対するGraylog以外のアクセスを制限し直接ESにアクセスされるのを防ぐことが出来ます。
Graylog は多機能なシステムであり、ログを整形したり、アラートを飛ばしたり、他のシステムにログをフォワードしたりすることも出来ます。 marketplace でサードパーティの plugin が公開されており、機能を拡張することが出来ます。 APIも提供されており、ある程度自動化が可能です。
認証・認可 オンプレミスでログを管理する場合、社外からは勿論社内からのアクセスも制限したいです。 Graylog では LDAP や Active Directory によってアクセスを制限できます。 リソース毎に誰が何を出来るか設定できます。
http://docs.graylog.org/en/2.5/pages/users_and_roles/external_auth.html
ログの収集 ログの収集をするには Graylog で幾つかのリソースを作成する必要があります。
 Input Index Set Stream Stream Rule  Input はログの入力のフォーマットの設定であり、 どのポートでどういったフォーマットのログを受け付けるかという設定になります。 フォーマットは様々なものがサポートされています。
 AWS Flow Logs AWS Cloud Watch Logs AWS Cloud Trail Beats CEF AMQP CEF Kafka CEF TCP CEF UDP Fake HTTP Message GELF AMQP GELF HTTP GELF Kafka GELF TCP GELF UDP JSON Path NetFlow UDP Raw AMQP Syslog AMQP Syslog Kafka Syslog TCP Syslog UDP  この設定はログを収集するアプリケーションごとに設定するというより、グローバルな設定なので、他のアプリケーションで既に同じ形式でログを収集していたら新たに設定する必要はありません。</description>
    </item>
    
    <item>
      <title>akoi - binary installer</title>
      <link>https://suzuki-shunsuke.github.io/akoi/</link>
      <pubDate>Wed, 31 Oct 2018 08:56:04 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/akoi/</guid>
      <description>自作のOSS akoi の紹介をします。
 なぜこんなものを作ったのか akoi と ansible を使ってサーバにバイナリをインストールする方法  について主に説明します。
まとめ  akoi はバイナリファイルのインストーラ 設定ファイルで管理できる 冪等であり、効率よくインストールできる  並列インストール Accept-Ranges による分散ダウンロード  ansibleでサーバにバイナリをインストールするのを補助してくれる  ansible で真面目にバージョンコントロールして効率よくインストールするのは難しい(ほとんどの ansible role は出来ていない)   akoi とは akoi はバイナリファイルのインストーラです。 設定ファイルにインストールするファイルのダウンロードURLとインストール先を記述して管理します。 インストールするバイナリのバージョン管理が可能であり、既にインストールしてあるバージョンへの切り替えはシンボリックを作り直すだけなので一瞬で終わります。無駄にダウンロードをしたりはしません。 複数のバイナリを並列でインストールしたり、Accept-Ranges ヘッダによる分散ダウンロードをサポートしています。
分散ダウンロードについては
https://qiita.com/codehex/items/d0a500ac387d39a34401
が参考になります。
Goで書かれています。
https://github.com/suzuki-shunsuke/akoi/releases からバイナリをダウンロードしてインストールできます。
詳細はREADMEを読んでください。
なぜ作ったのか サーバにバイナリをインストールする ansible role を書くのが辛かったからです。 最近は色々なソフトウェアがGoで書かれ、バイナリで配布されています。 そういったバイナリをサーバへインストールするのは ansible で行っているという方も少なくないのではないでしょうか？ 有名なソフトウェアをインストールする ansible role は大抵Ansible Galaxy で公開されています。
しかし、ほとんどの role は「真面目に」バージョン管理していません。 ここでいう「真面目に」とは
 バージョンを指定できる バージョンを変更できる 指定したバージョンが既にインストールされている場合は無駄にダウンロードしたりしない  といったことです。</description>
    </item>
    
    <item>
      <title>gomic - Goのモックジェネレータ</title>
      <link>https://suzuki-shunsuke.github.io/gomic/</link>
      <pubDate>Tue, 30 Oct 2018 08:35:16 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/gomic/</guid>
      <description>自作のOSS gomic の紹介をします。
 なぜわざわざこんなものを作ったのか 生成されたモックの簡単な使い方  を主に説明したいと思います。
まとめ  gomic は Goのinterfaceを実装したモックを生成するCLIツール モックを手で書くのが辛すぎた &amp;amp; 既存ツールで満足できなかったため作った  自動生成できるコードは自動生成すべき  設定ファイルで管理するため、interfaceの更新に合わせてmockの更新が容易 生成されるモックはシンプルなAPIのみ提供するので学習コストが低い  gomic とは gomic は Goのinterfaceを実装したモックを生成するCLIツールです。 これによってモックを使ったテストの作成を効率化します。 単調な作業を自動化し、本来注力すべきことに注力できるようにするためのツールです。
Goで書かれています。
https://github.com/suzuki-shunsuke/gomic/releases からバイナリをダウンロードしてインストールできます。
同様のツールは幾つかあります。
 https://github.com/avelino/awesome-go#testing https://github.com/golang/mock (以下 gomock) https://github.com/gojuno/minimock (以下 minimock)  特に gomock は有名ですね。
なぜ作ったのか 上述のように既に同様のツールはありますし、 gomock と minimock は試しました。 しかしあまり満足のいくものではなかったため、自分で作ることにしました。
自分が欲しかったのは学習コストの低いシンプルなAPIです。 interfaceのメソッドを実装した関数をモックに渡すことで 簡単にメソッドの実装を切り替えたいのです。
// Getwd メソッドのモック mock.SetFuncGetwd(func() (string, error) { return &amp;quot;/tmp&amp;quot;, nil }) mock.Getwd() // &amp;quot;/tmp&amp;quot;, nil  これは非常にシンプルで分かりやすく、柔軟性のあるパターンです(minimockはこのパターンもサポートしています)。</description>
    </item>
    
    <item>
      <title>Dockerを使ってansible playbookをテストする</title>
      <link>https://suzuki-shunsuke.github.io/test-ansible-on-docker/</link>
      <pubDate>Fri, 12 Oct 2018 21:02:51 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/test-ansible-on-docker/</guid>
      <description>ansible playbookを(VMの代わりに)Dockerコンテナに対して実行すると、効率よく動作確認できるというお話です。 ansible playbookの動作確認のためにvagrantでVMを起動したりしていると動作確認に時間がかかるし、容量も喰います。 Dockerコンテナを使って動作確認できればこれらの問題を解決できます。
ただし、Dockerコンテナの場合、一部のansible のtaskが失敗することがあるので ansible playbookによってはDockerコンテナではテストにならない場合もあるかと思います。
サンプル https://github.com/suzuki-shunsuke/example/tree/master/ansible/test-on-docker
簡単なサンプルを用意しました。
ansible playbookに加え、
 docker-compose.yml test_docker.sh: 簡単なシェルスクリプト  を作成してあります。
$ bash test_docker.sh  とすることで動作確認できます。
説明 スクリプトでやっていることは
 Docker Compose でコンテナを起動 コンテナのIDを取得し、inventory ファイルを作成 Docker Connection Pluginを使ってコンテナにplaybookを実行  です。
Docker Connection Plugin を使うとDockerコンテナに対してansible playbookを実行できます。
 https://docs.ansible.com/ansible/2.6/plugins/connection.html https://docs.ansible.com/ansible/2.6/plugins/connection/docker.html  また、Docker Hubで公開されている多くのDockerイメージのUSERは root ですが、 ansible playbookの動作確認としては都合が悪かったりします。
そこで自分は非rootユーザーを作成したDocker Imageを使っています。
https://hub.docker.com/r/suzukishunsuke/ansible-test-centos/
関係ありそうなツール 今回は簡単なスクリプトとdocker-compose.ymlを用意しましたが、 もっとイケてるやり方がありそうなものです。
Vagrant Docker Provider https://www.vagrantup.com/docs/docker/
なんかあまり使えなさそうです。 Linux以外だと結局VMが必要で、既に非推奨な boot2docker をデフォルトでは使うらしくだめそうだなって思いました。 あまり調べてません。
https://www.vagrantup.com/docs/docker/basics.html#host-vm</description>
    </item>
    
    <item>
      <title>Project site を User site に移行しました (GitHub Pages)</title>
      <link>https://suzuki-shunsuke.github.io/migrate-to-user-gh-pages/</link>
      <pubDate>Wed, 10 Oct 2018 21:14:03 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/migrate-to-user-gh-pages/</guid>
      <description>なんとなく試験的に Project site でホスティングしていた GitHub Pages を User site に移行しました。
source code は source branch にあります。
CIに関しては Hugo製ブログをGitHub PagesへCIでデプロイ にも書きましたが参考になる部分もあるかもしれません。</description>
    </item>
    
    <item>
      <title>Hugo製ブログをGitHub PagesへCIでデプロイ</title>
      <link>https://suzuki-shunsuke.github.io/how-to-host-hugo-at-github-pages/</link>
      <pubDate>Mon, 01 Oct 2018 08:04:16 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/how-to-host-hugo-at-github-pages/</guid>
      <description>https://gohugo.io/ と https://pages.github.com/ の話です。 master に push したら GitHub Pages に circle ciでデプロイするようにする方法の紹介です。
前提  テーマは master branch に含めない(CIでcloneする) buildしたものは gh-pages ブランチにデプロイ  コード .circleci/config.yml
--- version: 2 jobs: build: docker: - image: suzukishunsuke/hugo-ci:0.1.2 steps: - checkout - run: git config user.name &amp;quot;***&amp;quot; - run: git config user.email &amp;quot;***@example.com&amp;quot; # --depth 1 で高速化 - run: git clone --depth 1 https://github.com/suzuki-shunsuke/tale-hugo themes/tale - run: hugo - run: sh release.sh workflows: version: 2 build: jobs: - build: filters: branches: only: master  release.</description>
    </item>
    
    <item>
      <title>travis ci から circle ci への移行のすすめ</title>
      <link>https://suzuki-shunsuke.github.io/migrate-from-travis-ci-to-circle-ci/</link>
      <pubDate>Mon, 01 Oct 2018 07:23:15 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/migrate-from-travis-ci-to-circle-ci/</guid>
      <description>travis ci と circle ci の無償SaaS 版を比較しています。
OSS の CI では travis ci がよく使われる印象がありますが、 場合によっては circle CI に移行するとCIの時間が大幅に短くなったりして良いと思います。 ただし、複数バージョンで並列にテストしたい場合、circle ci の無償planだと並列に実行できないため、 travis でやったほうが速いかもしれません。
Circle CI の良いところ  好きな Docker Image が使える ローカルでテストが出来る Pending 時間が travis ci に比べて短い気がする(主観) private repository の CI も出来る  好きな Docker Image が使えるのが大きいですね。 予め CI に必要なツールをインストールした Image を用意しておくことで大幅に高速化出来ますし、 ツールがインストールできなかったりバージョンが変わってしまったりするトラブルも避けられます。 同じImageを使ってローカルでテストできるのでローカルでの検証もしやすいです。
自分の場合 Golang のツールの CI用に Docker Image を用意しています。
https://hub.docker.com/r/suzukishunsuke/go-ci/</description>
    </item>
    
    <item>
      <title>metabase を使って drone の利用状況を可視化する</title>
      <link>https://suzuki-shunsuke.github.io/visualize-drone-usage-by-metabase/</link>
      <pubDate>Sun, 30 Sep 2018 22:55:57 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/visualize-drone-usage-by-metabase/</guid>
      <description> drone OSS 0.8.5 で検証しています。
https://drone.io/ と https://www.metabase.com/ の話です。
drone の利用状況を可視化したかったので、 drone の DB(MySQL) のデータを metabase で可視化しました。
どんなグラフを作ったのか いざグラフを作成するとなると、何を作ったらいいのか迷いましたが、以下のようなものをとりあえず作ってみました。
 ユーザー数 有効化されたリポジトリ数 buildの多いリポジトリ buildをよく実行しているユーザー ビルド時間の分布 build event の割合(push, tag, pull request, deployment) リポジトリのsecretsの数の分布  </description>
    </item>
    
    <item>
      <title>drone の管理のために portainer を導入した</title>
      <link>https://suzuki-shunsuke.github.io/use-portainer-for-drone-admin/</link>
      <pubDate>Sun, 30 Sep 2018 21:56:42 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/use-portainer-for-drone-admin/</guid>
      <description>drone OSS 0.8.5 で検証しています。
https://drone.io/ と https://portainer.io/ の話です。
drone はかなり安定したシステムだと思いますが、 ユーザーが好きなイメージで好きなコマンドを実行できる以上、トラブルが起こることはあります。
その結果、 特定の build がタイムアウトにならずに延々と実行され続けるなんてことがあります。
その場合、
 どのノードのどのコンテナでトラブルが起きているのか そのコンテナで何が起こっているのか  というのを知りたいのですが、 drone にはそういった管理機能はありません。
そこで 複数のサーバで実行されている Docker コンテナを管理できるツールはないかと探したところ、 portainer が良さそうだったので導入しました。
portainer を使うと複数のサーバのコンテナを一覧で見ることが出来、 コンテナを操作(削除、停止、再起動etc)出来ます。 コンテナのログや簡単なメトリックス(CPU, memory, network usage) が見れます。 コンテナだけでなく、network や volume, image といったリソースも管理できます。
portainer の導入 公式ドキュメントに書いてありますが、 swarm cluster を構築してそこにデプロイすればよいです。
 https://docs.docker.com/engine/swarm/swarm-tutorial/ https://portainer.readthedocs.io/en/stable/deployment.html#inside-a-swarm-cluster  困っていること 毎回検索で絞り込みしないといけない 検索で絞り込んだ後に特定のコンテナの詳細画面飛んだ後一覧に戻ると 検索がクリアされているのでもう一度検索しないといけないのが面倒です。
もう少し高度な検索がしたい 自由入力の検索ボックスが1つあるだけで、特にクエリが書けるわけでもなさそうなので、 もう少し高度な検索がしたいです。 例えば Created At で 1時間以上前に特定のノードで作られたコンテナの一覧とか。
docker API でエラーが出て、コンテナを操作できない これは多分不具合とかではなく自分の設定が良くないのだと思います。 この辺の issue が関係してそうですが、まだ解消できていません。</description>
    </item>
    
    <item>
      <title>drone で非rootユーザーで実行されるImageを使えない</title>
      <link>https://suzuki-shunsuke.github.io/drone-cant-use-nonroot-image/</link>
      <pubDate>Sun, 30 Sep 2018 21:42:16 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-cant-use-nonroot-image/</guid>
      <description>drone で非rootユーザーで実行されるDocker Imageを使おうとするとbuildに失敗します。
/bin/sh: 3: cannot create /root/.netrc: Permission denied  これについては drone の開発者が回答しています。
 https://discourse.drone.io/t/solved-netrc-permission-denied/171/2 https://discourse.drone.io/t/solved-netrc-permission-denied/171/4  結論を言うと、 他のイメージを使うか、 rootで実行されるようにイメージを修正する必要がありそうです。</description>
    </item>
    
    <item>
      <title>drone の step を実行するか否かをタグ名で判定する方法</title>
      <link>https://suzuki-shunsuke.github.io/drone-tag-conditional-step/</link>
      <pubDate>Sun, 30 Sep 2018 21:30:06 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-tag-conditional-step/</guid>
      <description>drone 0.8.5 で検証しています。
tag 名による判定方法はドキュメントには書いてないので書いておきます。
when: ref: refs/tags/foo-* # タグ名が foo-* ならステップを実行  グロブ * には / は含まれないことには注意してください。
上記の例だと、 tag foo/bar/0.1.0 はマッチしません。 これは Go の filepath.Match を使っているからです。
 https://github.com/cncd/pipeline/blob/f8c48fc9fb9fd113c6e7dd941d63bb9f86a623cb/pipeline/frontend/yaml/constraint.go#L70 https://github.com/cncd/pipeline/blob/f8c48fc9fb9fd113c6e7dd941d63bb9f86a623cb/pipeline/frontend/yaml/constraint.go#L80  </description>
    </item>
    
    <item>
      <title>drone の project visibility とは</title>
      <link>https://suzuki-shunsuke.github.io/drone-project-visibility/</link>
      <pubDate>Sun, 30 Sep 2018 20:32:20 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-project-visibility/</guid>
      <description>恐らく公式ドキュメントに説明がない気がするので書いておきます。 と言っても、以下のissueに全部書いてありますが。
https://github.com/drone/drone/issues/2042
droneの web ui からリポジトリごとに設定できます。 そのリポジトリが誰に見えるかの設定です。
 public: ログインしていなくても誰でも見れる(publicリポジトリのデフォルト) private: リポジトリにアクセスできる人しか見れない(privateリポジトリのデフォルト) internal: ログインしていれば誰でも見れる  </description>
    </item>
    
    <item>
      <title>drone の matrix build が27個しか実行されない</title>
      <link>https://suzuki-shunsuke.github.io/drone-matrix-build-run-only-27/</link>
      <pubDate>Sun, 30 Sep 2018 20:26:11 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-matrix-build-run-only-27/</guid>
      <description>drone 0.8.5 で検証しています。
matrix: ZOO: - 1 - 2 - 3 - 4 FOO: - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 BAR: - 1 - 2  上記の場合、本来 4 * 8 * 2 = 64 個実行されるはずのmatrix builds が27個しか実行されなかったのでソースコードを確認したところ、 27個しか実行されないようにハードコードされていました。
 https://github.com/cncd/pipeline/blob/d4e09fd3021a16408bc3ebdd3500efd28f51e72c/pipeline/frontend/yaml/matrix/matrix.go#L11 https://github.com/cncd/pipeline/blob/d4e09fd3021a16408bc3ebdd3500efd28f51e72c/pipeline/frontend/yaml/matrix/matrix.go#L93  関係ある部分だけ抽出すると以下のような感じになります。
limitAxis = 25 axisList := []Axis{} for p := 0; p &amp;lt; perm; p++ { axisList = append(axisList, axis) if p &amp;gt; limitAxis { break } }  制限をかけるのは仕方ないですが、 エラーも warning もなく正常終了し、でもよく見ると 27 個しか実行されていないので ユーザーとしては混乱しますね。 build の結果の画面の上の方に warning があると嬉しいです。</description>
    </item>
    
    <item>
      <title>drone の build の timeout が変更できない</title>
      <link>https://suzuki-shunsuke.github.io/drone-build-timeout/</link>
      <pubDate>Sun, 30 Sep 2018 20:16:28 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-build-timeout/</guid>
      <description>drone 0.8.5 で検証しています。
drone の build の タイムアウトの設定はリポジトリの settings から変更できそうですが、 実は drone の admin しか変更できません。
ブラウザのデベロッパーツールを使うと、この Timeout の設定を変更した際に
PATCH /api/repos/:owner/:name  にリクエストが飛んでいるので、そこからコードを追いかけると分かります。
 https://github.com/drone/drone/blob/29785b86f6534ded974120de0fcf7c21397a9d0d/router/router.go#L109 https://github.com/drone/drone/blob/29785b86f6534ded974120de0fcf7c21397a9d0d/server/repo.go#L117  </description>
    </item>
    
    <item>
      <title>Drone の build 実行時の認証方法</title>
      <link>https://suzuki-shunsuke.github.io/drone-git-authentication/</link>
      <pubDate>Sun, 30 Sep 2018 19:44:27 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-git-authentication/</guid>
      <description>drone の build における GitHub (GitHub前提で書きますが、GitHub以外でも同じだと思います) の認証の話(どうやって認証しているか)について書いておこうと思います。 drone の build は clone step で対象のリポジトリを GitHub から clone してきています。 この際に何かしらの方法で認証しているはずです。
結論を言うと、
あるリポジトリAのbuildでは、 リポジトリAの drone連携を有効化したユーザー Bの access token を .netrc に書き込んで認証しています。 よってユーザーBにcloneする権限があるリポジトリはcloneできるし、 ユーザーBにcloneする権限がないリポジトリはcloneできません。 つまり、 誰が連携を有効化するかが重要 になります(これについては後述します)。 なお、drone連携の有効化はそのリポジトリのowner以上でないと出来ません。
drone上でリポジトリの連携を有効化すると、 リポジトリのHookが作成されます。 リポジトリの settings &amp;gt; Hooks から確認できます。 この Hook の Payload URL を見ると access_token クエリがあると思います。 JWTのようですね。これはリポジトリの連携を有効化したユーザーのtokenです。
このtokenが GitHub から drone への webhook のパラメータとして送られてくるので、 drone 側で認証し、認証したユーザーのGitHub のaccess token を取得し、 build 時にコンテナの /root/.netrc に書き込むようです。
.netrcに書き込まれているのは試しに個人の private repository で .</description>
    </item>
    
    <item>
      <title>Drone と Circle CI の workspace の扱いの違いについて</title>
      <link>https://suzuki-shunsuke.github.io/drone-circle-volume-difference/</link>
      <pubDate>Sun, 30 Sep 2018 19:27:59 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-circle-volume-difference/</guid>
      <description>drone は同じ pipeline の step 間で同じ workspace を docker の volume としてマウントすることで workspace を共有します。
http://docs.drone.io/workspace/
circle ci はデフォルトで job 間で workspace を共有しません。 persist_to_workspace を指定することで共有する事ができます。
https://circleci.com/docs/2.0/workflows/#using-workspaces-to-share-data-among-jobs
circle ci の場合は volume を共有するのではなく、指定したディレクトリを archive し、次の job で展開することでファイルを共有するようです。
この違いには一長一短があります。
circle ci の場合は archive, unarchive する分、volume 共有に比べて時間がかかります。
そのため、下手に job を分けるより一つの job で処理したほうが処理時間が短くなる場合がありますが、 build や test といった処理は出来れば別の job として実行したいでしょうし、それでは workflow が使えません。
ただし、共有するパスは自由に選べるので必要最小限に抑えることで時間を短縮できます。
また、circle ci の場合は archive するパス及び展開先のパスを自由に選べるので自由度が高いです。 drone の場合、 workspace 以外のファイルを共有できません。
また、drone の場合 volume を共有するので同じ pipeline の step は同じノードで実行されるという制約がありますが、 circle ci の場合、別のノードでの実行が可能です。 drone の group を使って並列に実行する場合、複数のノードに分散できませんが、 circle ci の場合分散できるのでよりスケールしやすいと言えるでしょう。</description>
    </item>
    
    <item>
      <title>drone exec を並列実行した際のdocker network name の衝突について</title>
      <link>https://suzuki-shunsuke.github.io/drone-exec-network-name-collision/</link>
      <pubDate>Sun, 30 Sep 2018 18:52:34 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/drone-exec-network-name-collision/</guid>
      <description>drone exec を並列実行すると docker network name が衝突することがあります。
$ drone exec --local &amp;amp; drone exec --local [1] 42934 2018/06/06 01:58:12 Error response from daemon: network drone_default is ambiguous (4 matches found on name) 2018/06/06 01:58:12 Error response from daemon: Conflict. The container name &amp;quot;/drone_step_0&amp;quot; is already in use by container &amp;quot;464a29b0726d6ff1a352d81df9c837330501085be550bb16abac3d338dfad887&amp;quot;. You have to remove (or rename) that container to be able to reuse that name. [1] + exit 1 drone exec --local  drone は pipeline 実行時に network を作成し、pipeline が終了すると network を削除します。</description>
    </item>
    
    <item>
      <title>go-gencfg - viperの個々のアプリケーション用のラッパーのコードジェネレータ</title>
      <link>https://suzuki-shunsuke.github.io/go-gencfg/</link>
      <pubDate>Thu, 06 Sep 2018 23:59:35 +0900</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/go-gencfg/</guid>
      <description>自作のOSS go-gencfg を紹介します。 Golang で viper という汎用的な設定管理ライブラリがありますが、 特定のアプリケーション用に viper のラッパーを生成するCLIツールです。
使い方や開発の背景を書こうかと思いましたが、だいたい README に書いてあるので そちらを御覧ください。
https://github.com/suzuki-shunsuke/go-gencfg/blob/master/README.md</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://suzuki-shunsuke.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://suzuki-shunsuke.github.io/about/</guid>
      <description> https://github.com/suzuki-shunsuke/profile  </description>
    </item>
    
  </channel>
</rss>